import torch
import esm
import sys

# Check if the correct number of command-line arguments are provided
if len(sys.argv) != 2:
    print("Usage: python3 script.py <sequence_id>")
    sys.exit(1)

# Get the sequence ID from the command-line arguments
user_input = sys.argv[1]

print("Building model...")
model = esm.pretrained.esmfold_v1()
print("Evaluating model...")
model = model.eval().cuda()

# Optionally, uncomment to set a chunk size for axial attention. This can help reduce memory.
# Lower sizes will have lower memory requirements at the cost of increased speed.
# model.set_chunk_size(128)

#Isoform X1
if user_input == "A1":
    sequence = "MGVIFYLTIALTAMLATLSQAQRAQAPLDTTGKEFVFAFQSNFQNKRPDKLSLLIGANEPGLTRVQIEAPNFNWQQTVQLQHKQVRNVDINPDVAARGAGPVNGTLIVRATKDVSISGLNSLTMTNDAFLAIPTHGLGQEYYVASYDPVPIEMSQFLITGIQPDTSVKIVLQARLQHNSQWYSKGQTLTVNVGKYQSIQFQSQEDLTGTKITSTKPLSVMSGASCTLVPTQVYRCDHLVEHLPPFNTWGKRFTLLPFSNRSGGFIFRIIAGRPSTTVHIMGNNVQLQFEGSFREFNQPASLKTTLQSDKPIMVVQYAKGMQKDNNGDPFMTLIPPVEQYMEKEITFGSFNQSGTDMLNMFAGVSFTSPALFTMSLNGKPAFEPSTGIPGTGISRTFTADATVPLDDVRNILTNYEKDVRFMAVIYGFASGTSFGYPAAYQLRQLTCTRPGRQGPEAEYDCPETHRRPRPTAPVVPVGPGGGGDGAAMTGCTSKGVVVLAAILPALIVFIIMVIILVFVLYRNPSSPELQKFKMFFRVNPRERTISRCSFVRNGSL"
    output_file = "resultA1.pdb"
elif user_input == "A2":
#Isoform X2 IgGFc-binding protien
    sequence = "MGVIFYLTIALTAMLATLSQAQRAQAPLDTTGKEFVFAFQSNFQNKRPDKLSLLIGANEPGLTRVQIEAPNFNWQQTVQLQHKQVRNVDINPDVAARGAGPVNGTLIVRATKDVSISGLNSLTMTNDAFLAIPTHGLGQEYYVASYDPVPIEMSQFLITGIQPDTSVKIVLQARLQHNSQWYSKGQTLTVNVGKYQSIQFQSQEDLTGTKITSTKPLSVMSGASCTLVPTQVYRCDHLVEHLPPFNTWGKRFTLLPFSNRSGGFIFRIIAGRPSTTVHIMGNNVQLQFEGSFREFNQPASLKTTLQSDKPIMVVQYAKGMQKDNNGDPFMTLIPPVEQYMEKEITFGSFNQSGTDMLNMFAGVSFTSPALFTMSLNGKPAFEPSTGIPGTGISRTFTADATVPLDDVRNILTNYEKDVRFMAVIYGFASGTSFGYPAAYQLRQLTCTRPGRQGPEAEYDCPETHRRPRPTAPVVPVGPGGGGDGAAMTGCTSKGVVVLAAILPALIVFIIMVIILVFVLYRGGLYKNF"
    output_file = "resultA2.pdb"
elif user_input == "A3":
#Isoform X3 IgGFc-binding protein
    sequence = "MGVIFYLTIALTAMLATLSQAQRAQAPLDTTGKEFVFAFQSNFQNKRPDKLSLLIGANEPGLTRVQIEAPNFNWQQTVQLQHKQVRNVDINPDVAARGAGPVNGTLIVRATKDVSISGLNSLTMTNDAFLAIPTHGLGQEYYVASYDPVPIEMSQFLITGIQPDTSVKIVLQARLQHNSQWYSKGQTLTVNVGKYQSIQFQSQEDLTGTKITSTKPLSVMSGASCTLVPTQVYRCDHLVEHLPPFNTWGKRFTLLPFSNRSGGFIFRIIAGRPSTTVHIMGNNVQLQFEGSFREFNQPASLKTTLQSDKPIMVVQYAKGMQKDNNGDPFMTLIPPVEQYMEKEITFGSFNQSGTDMLNMFAGVSFTSPALFTMSLNGKPAFEPSTGIPGTGISRTFTADATVPLDDVRNILTNYEKDVRFMAVIYGFASGTSFGYPAAYQLRQLTCTRPGRQGPEAEYDCPETHRRPRPTAPVVPVGPGGGGDGAAMTGCTSKGVVVLAAILPALIVFIIMVIILVFVLYRMRRKF"
    output_file = "resultA3.pdb"
# Multimer prediction can be done with chains separated by ':'

print("Model ready. Inferring sequence...")
with torch.no_grad():
    output = model.infer_pdb(sequence)

with open(output_file, "w") as f:
    f.write(output)

import biotite.structure.io as bsio
struct = bsio.load_structure(output_file, extra_fields=["b_factor"])
print(struct.b_factor.mean())  # this will be the pLDDT
# 88.3



"""
#Run visualization using ESM
	interact --gpu
	conda activate esmfold
	mkdir esm_results
	cd esm_results
	#Obtain the results images
	python3 ../esm_qstart.py
	#Obtain the visualization PDB file
	python3 ../esm_nstart.py
	cd ..
	
    """
    